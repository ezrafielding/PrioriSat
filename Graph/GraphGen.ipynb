{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, segmentation, filters, color, io\n",
    "from skimage import graph\n",
    "from matplotlib import pyplot as plt\n",
    "from GraphGen.gen import nxgraph_to_adj_matrix, gen_properties\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_boundary(graph, src, dst, n):\n",
    "    \"\"\"\n",
    "    Handle merging of nodes of a region boundary region adjacency graph.\n",
    "\n",
    "    This function computes the `\"weight\"` and the count `\"count\"`\n",
    "    attributes of the edge between `n` and the node formed after\n",
    "    merging `src` and `dst`.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : RAG\n",
    "        The graph under consideration.\n",
    "    src, dst : int\n",
    "        The vertices in `graph` to be merged.\n",
    "    n : int\n",
    "        A neighbor of `src` or `dst` or both.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        A dictionary with the \"weight\" and \"count\" attributes to be\n",
    "        assigned for the merged node.\n",
    "\n",
    "    \"\"\"\n",
    "    default = {'weight': 0.0, 'count': 0}\n",
    "\n",
    "    count_src = graph[src].get(n, default)['count']\n",
    "    count_dst = graph[dst].get(n, default)['count']\n",
    "\n",
    "    weight_src = graph[src].get(n, default)['weight']\n",
    "    weight_dst = graph[dst].get(n, default)['weight']\n",
    "\n",
    "    count = count_src + count_dst\n",
    "    return {\n",
    "        'count': count,\n",
    "        'weight': (count_src * weight_src + count_dst * weight_dst)/count\n",
    "    }\n",
    "\n",
    "\n",
    "def merge_boundary(graph, src, dst):\n",
    "    \"\"\"Call back called before merging 2 nodes.\n",
    "\n",
    "    In this case we don't need to do any computation here.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def get_text(text_data, filename):\n",
    "    classname = filename[:-8]\n",
    "    for entry in text_data[classname]:\n",
    "        if entry.get(\"filename\") == filename:\n",
    "            \n",
    "            return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../datasets/NWPU-Captions/dataset_nwpu.json', 'r')\n",
    "text_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../datasets/NWPU-Captions/NWPU_images/'\n",
    "test_adjs = []\n",
    "test_desc = []\n",
    "train_adjs = []\n",
    "train_desc = []\n",
    "val_adjs = []\n",
    "val_desc = []\n",
    "\n",
    "train_properties = []\n",
    "test_properties = []\n",
    "val_properties = []\n",
    "\n",
    "for classname in text_data:\n",
    "    print(\"Current class: \", classname)\n",
    "    class_path = os.path.join(base_path, classname)\n",
    "    for entry in text_data[classname]:\n",
    "        try:\n",
    "            img = io.imread(os.path.join(class_path, entry['filename']))\n",
    "        except:\n",
    "            continue\n",
    "        edges = filters.sobel(color.rgb2gray(img))\n",
    "        labels = segmentation.slic(img, compactness=30, n_segments=400, start_label=1)\n",
    "        g = graph.rag_boundary(labels, edges)\n",
    "\n",
    "        labels2 = graph.merge_hierarchical(labels, g, thresh=0.08, rag_copy=False,\n",
    "                                        in_place_merge=True,\n",
    "                                        merge_func=merge_boundary,\n",
    "                                        weight_func=weight_boundary)\n",
    "        adj = nxgraph_to_adj_matrix(g)\n",
    "        properties = gen_properties([adj])\n",
    "        if entry['split'] == 'train':\n",
    "            for i in range(5): train_adjs.append(adj)\n",
    "            train_desc.append(entry['raw'])\n",
    "            train_desc.append(entry['raw_1'])\n",
    "            train_desc.append(entry['raw_2'])\n",
    "            train_desc.append(entry['raw_3'])\n",
    "            train_desc.append(entry['raw_4'])\n",
    "            train_properties.extend(properties)\n",
    "        elif entry['split'] == 'test':\n",
    "            for i in range(5): test_adjs.append(adj)\n",
    "            test_desc.append(entry['raw'])\n",
    "            test_desc.append(entry['raw_1'])\n",
    "            test_desc.append(entry['raw_2'])\n",
    "            test_desc.append(entry['raw_3'])\n",
    "            test_desc.append(entry['raw_4'])\n",
    "            test_properties.extend(properties)\n",
    "        else:\n",
    "            for i in range(5): val_adjs.append(adj)\n",
    "            val_desc.append(entry['raw'])\n",
    "            val_desc.append(entry['raw_1'])\n",
    "            val_desc.append(entry['raw_2'])\n",
    "            val_desc.append(entry['raw_3'])\n",
    "            val_desc.append(entry['raw_4'])\n",
    "            val_properties.extend(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('../datasets/NWPU-Captions/train', 'graphs.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_adjs, f)\n",
    "with open(os.path.join('../datasets/NWPU-Captions/train', 'properties.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_properties, f)\n",
    "with open(os.path.join('../datasets/NWPU-Captions/train', 'descriptions.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_desc, f)\n",
    "\n",
    "with open(os.path.join('../datasets/NWPU-Captions/test', 'graphs.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_adjs, f)\n",
    "with open(os.path.join('../datasets/NWPU-Captions/test', 'properties.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_properties, f)\n",
    "with open(os.path.join('../datasets/NWPU-Captions/test', 'descriptions.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_desc, f)\n",
    "\n",
    "with open(os.path.join('../datasets/NWPU-Captions/val', 'graphs.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_adjs, f)\n",
    "with open(os.path.join('../datasets/NWPU-Captions/val', 'properties.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_properties, f)\n",
    "with open(os.path.join('../datasets/NWPU-Captions/val', 'descriptions.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_desc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('../datasets/NWPU-Captions/NWPU_images/airplane/airplane_621.jpg')\n",
    "edges = filters.sobel(color.rgb2gray(img))\n",
    "labels = segmentation.slic(img, compactness=30, n_segments=400, start_label=1)\n",
    "g = graph.rag_boundary(labels, edges)\n",
    "\n",
    "labels2 = graph.merge_hierarchical(labels, g, thresh=0.08, rag_copy=False,\n",
    "                                   in_place_merge=True,\n",
    "                                   merge_func=merge_boundary,\n",
    "                                   weight_func=weight_boundary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detour",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

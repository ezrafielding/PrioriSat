{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDesc(filename):\n",
    "    try:\n",
    "        bb_file = pd.read_csv(filename, sep=' ', header=None, skiprows=[0,1])\n",
    "        counts = bb_file[8].value_counts()\n",
    "        text = 'A remote sensing image containing '\n",
    "        prop = []\n",
    "        for label, count in counts.items():\n",
    "            text = text + str(count) + ' ' + label.replace('-', ' ') + 's, '\n",
    "            class_prop = {'class':label, 'count': count}\n",
    "            if count >1:\n",
    "                class_info = bb_file[bb_file[8]==label].drop(9, axis=1)\n",
    "                class_info['x_centroid'] = class_info[[0,2,4,6]].sum(axis=1)/4\n",
    "                class_info['y_centroid'] = class_info[[1,3,5,7]].sum(axis=1)/4\n",
    "                avg_spread = pdist(class_info[['x_centroid', 'y_centroid']].values).mean()\n",
    "                class_prop['avg_spread'] = avg_spread\n",
    "            else:\n",
    "                class_prop['avg_spread'] = None\n",
    "            prop.append(class_prop)\n",
    "        text = text[:-2] + \".\"\n",
    "        return text, prop\n",
    "    except:\n",
    "        return 'A satellite image.', []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions = []\n",
    "val_descriptions = []\n",
    "train_dir = '../datasets/DOTAv1.5/labels/train_original/'\n",
    "val_dir = '../datasets/DOTAv1.5/labels/val_original/'\n",
    "train_files = [f for f in os.listdir(train_dir)]\n",
    "val_files = [f for f in os.listdir(val_dir)]\n",
    "\n",
    "for f in train_files:\n",
    "    src_path = os.path.join(train_dir, f)\n",
    "    desc, prop = genDesc(src_path)\n",
    "    dict = {\n",
    "        'filename': f,\n",
    "        'description': desc,\n",
    "        'properties': prop\n",
    "    }\n",
    "    train_descriptions.append(dict)\n",
    "\n",
    "for f in val_files:\n",
    "    src_path = os.path.join(val_dir, f)\n",
    "    desc, prop = genDesc(src_path)\n",
    "    dict = {\n",
    "        'filename': f,\n",
    "        'description': desc,\n",
    "        'properties': prop\n",
    "    }\n",
    "    val_descriptions.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/DOTAv1.5/descriptions/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../datasets/DOTAv1.5/descriptions/train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m      2\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(train_descriptions, outfile)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/DOTAv1.5/descriptions/val.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n",
      "File \u001b[0;32m~/miniconda3/envs/priorisat/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/DOTAv1.5/descriptions/train.json'"
     ]
    }
   ],
   "source": [
    "with open(\"../datasets/DOTAv1.5/descriptions/train.json\", \"w\") as outfile:\n",
    "    json.dump(train_descriptions, outfile)\n",
    "with open(\"../datasets/DOTAv1.5/descriptions/val.json\", \"w\") as outfile:\n",
    "    json.dump(val_descriptions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/DOTAv1.5/descriptions/train.txt\", \"w\") as outfile:\n",
    "    for desc in train_descriptions:\n",
    "        outfile.write(f\"<s>[INST] Genereate the object bounding box properties for a remote sensing image with the following description as JSON only: {desc['description']} [/INST] {str(desc['properties'])} </s> \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../datasets/DOTAv1.5/descriptions/val.txt\", \"w\") as outfile:\n",
    "    for desc in val_descriptions:\n",
    "        outfile.write(f\"<s>[INST] Genereate the object bounding box properties for a remote sensing image with the following description as JSON only: {desc['description']} [/INST] {str(desc['properties'])} </s> \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
